<!doctype html><html lang=en><head><title>The space of matrices where LU requires pivoting is almost full-dimensional | Gabriel H. Brown</title><meta name=viewport content="width=device-width,initial-scale=1"><meta charset=UTF-8><link rel=stylesheet href=//cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.2/css/all.min.css integrity="sha512-1sCRPdkRXhBV2PBLUdRb4tMg1w2YPf37qatUFeS7zlBy7jJI8Lf4VHwWfZZfpXtYSLy85pkm9GaYVYMfw5BC1A==" crossorigin=anonymous><link rel=stylesheet href=//cdnjs.cloudflare.com/ajax/libs/academicons/1.9.1/css/academicons.min.css integrity="sha512-b1ASx0WHgVFL5ZQhTgiPWX+68KjS38Jk87jg7pe+qC7q9YkEtFq0z7xCglv7qGIs/68d3mAp+StfC8WKC5SSAg==" crossorigin=anonymous><link rel=stylesheet href=https://ghbrown.net/css/palettes/color-splotch.css><link rel=stylesheet href=https://ghbrown.net/css/risotto.css><link rel=stylesheet href=https://ghbrown.net/css/custom.css><script src=https://ghbrown.net/assets/quotes.js></script><script src=https://ghbrown.net/js/serve_quote.js></script><script type=text/javascript src=//code.jquery.com/jquery-latest.min.js></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css integrity=sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js integrity=sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4 crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js integrity=sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa crossorigin=anonymous onload=renderMathInElement(document.body)></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script></head><body><div class=page><header class=page__header><nav class="page__nav main-nav"><ul><h1 class=page__logo><a href=https://ghbrown.net/ class=page__logo-inner>Gabriel H. Brown</a></h1><li class=main-nav__item><a class=nav-main-item href=https://ghbrown.net/ title>About Me</a></li><li class=main-nav__item><a class=nav-main-item href=https://ghbrown.net/topics/research title>Research</a></li><li class=main-nav__item><a class=nav-main-item href=https://ghbrown.net/topics/publications title>Publications</a></li><li class=main-nav__item><a class=nav-main-item href=https://ghbrown.net/topics/open_source title>Open Source</a></li><li class=main-nav__item><a class=nav-main-item href=https://ghbrown.net/topics/hobbies_and_interests title>Hobbies</a></li><li class=main-nav__item><a class=nav-main-item href=https://ghbrown.net/tags title>Post Topics</a></li></ul></nav></header><section class=page__body><div class=content__body><h1 id=the-space-of-matrices-requiring-pivoted-lu-factorization-is-almost-full-dimensional>The space of matrices requiring pivoted LU factorization is almost full-dimensional</h1><hr><p>The pivoted LU factorization of square matrices is the key routine for the direct solution of linear systems.
All square, invertible matrices have a pivoted LU factorization of the form $\mathbf{PA} = \mathbf{LU}$, where $\mathbf{P}$ is a permutation matrix and $\mathbf{L}, \; \mathbf{U}$ are respectively upper and lower triangular.</p><p>However, not all square, invertible matrices have a factorization of the form $\mathbf{A} = \mathbf{LU}$ (an LU factorization).
For example, consider the invertible matrix</p><p>$$
\mathbf{A} =
\begin{bmatrix}
0 & 1 \\
1 & 1
\end{bmatrix}
$$</p><p>for which the unpivoted LU algorithm will attempt to divide by 0 on the first iteration.
We will call such matrices &ldquo;pivot-required&rdquo;, meaning that they do not have a &ldquo;pure&rdquo; LU factorization $\mathbf{A} = \mathbf{LU}$ (even in infinite precision).</p><p>An interesting question regarding such matrices is: <em>what is the dimension of the set of pivot-required matrices</em>?</p><p>The answer, using elementary means is: <em>the set of pivot required matrices has dimension $n^2 - 1$</em>.</p><p>The full proof is presented below, but it is instructive to look at the $2 \times 2$ case first.
First, we see that the zero must be encountered in the upper left on the first iteration; since we are assuming the matrix is invertible, a zero will not be encountered on the second (read <em>last</em>) iteration.
Now, the set of full rank $2 \times 2$ matrices with a specified element equal to zero is 3-dimensional, and the generic part of this set admits the parameterization</p><p>$$
\begin{bmatrix}
0 & b \\
a & c
\end{bmatrix}
$$</p><p>which only fails to be full rank on sets of dimension 2 or 0 like</p><p>$$
\begin{bmatrix}
0 & 0 \\
a & c
\end{bmatrix}, \;
\begin{bmatrix}
0 & 0 \\
0 & 0
\end{bmatrix} .
$$</p><p>Since these &ldquo;voids&rdquo; in the set of pivot-required matrices are of dimension less than 3, the set of pivot-required $2 \times 2$ matrices has dimension 3.</p><p>Note that here $3 = 2^2 - 1$, which agrees with the general formula stated above and proven below.</p><details><summary>Proof</summary><p>As above, one can explicitly parameterize the space of $n \times n$ matrices for which unpivoted LU fails on the first iteration; now one finds that the dimension of this space is $n^2 - 1$.</p><p>However, there exist pivot-required matrices for which unpivoted LU fails on the $k$th iteration; for example, the following matrix has a failure on the second iteration:</p>$$
\begin{bmatrix}
1 & 1 & 0 \\
1 & 1 & 1 \\
1 & 0 & 0
\end{bmatrix} .
$$<p>In general, pivot-required matrices can cause failure on iterations $1, ..., n-1$, since generating a zero on the last iteration would imply the matrix is not full rank.</p><p>Therefore, we must ensure that the set of matrices which fail on iterations $2, ..., n-1$ also have dimension less than or equal to $n^2 - 1$.
In fact, we will prove constructively that such sets of matrices are also of dimension exactly $n^2 - 1$.</p><p>During the $j$ iteration of the unpivoted LU algorithm the following update is made to the trailing $n-j \times n-j$ submatrix</p>$$
\mathbf{B}_{j+1:,j+1:} \leftarrow \mathbf{B}_{j+1:,j+1:}
- \frac{1}{\mathbf{B}_{jj}} \mathbf{B}_{j+1:,j} \mathbf{B}_{j,j+1:} \; .
$$<p>Let $b_{ij}^{(p)}$ denote the $ij$th element of this submatrix after $p$ steps of the unpivoted LU algorithm.
Using the update rule for the complete matrix, we can write an update rule corresponding to iteration $p$ for a single element</p>$$
b_{ij}^{(p)} = b_{ij}^{(p-1)} -
\frac{1}{b_{pp}^{(p-1)}} b_{il}^{p-1} b_{lj}^{p-1}
$$<p>noting two important facts: $b_{ij}^{(0)} = a_{ij}$ (an element of the original matrix), this update formula only applies to elements in the submatrix $(i,j > p)$.</p><p>The condition for breakdown of the algorithm on the $k$th iteration is $b_{kk}^{(k-1)} = 0$.
Using the update formula and recurrence relationship, one can equivalently write this condition only in terms of the elements of the original matrix $\mathbf{A}$.
Further, applying this recurrence relationship only to the $b_{kk}^{(p)}$ term, one can see that the final result is an equation like $a_{kk} = f(a_{ij})$ where only $i = j = k$ is excluded.
Therefore, with only one of the $n^2$ variables dependent on the others, one can explicitly parameterize any such pivot-required matrix with $n^2 - 1$ parameters, hence this space is of dimension $n^2 - 1$.</p></details><hr><h3 id=comments-and-future-work>Comments and future work</h3><ul><li>Though this space is measure zero on the space of square matrices, it is still surprisingly large.</li><li>In finite precision this space would have finite measure, due to there being a finite number of floating point numbers.
I also suspect that the measure of matrices which induce breakdown in later iterations would be larger than the number of matrices which induce breakdown in the first iteration, due to the effects of rounding.</li><li>The main result presented here implies the following statement: generic \( n \times n \) matrices have an unpivoted LU factorization in infinite precision.</li><li>In practice, some sort of pivoting should almost always be used if the matrix does not have any known properties like being symmetric positive definite, etc.
This is because pivoting improves the stability of computing such a factorization, even when it is not strictly required.</li></ul></div><footer class=content__footer></footer></section><section class=page__aside><div class=aside__about><div id=quote><h1>A fun quote</h1></div><script>newQuote()</script></div><hr><div class=aside__content><p>posted 2023-06-06</p></div></section><footer class=page__footer><p class=copyright>Copyright <a href=/>Gabriel H. Brown</a>.</p></footer></div></body></html>